{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z21z-KfHiBu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997d8402-6424-476d-b564-52d3e02a07f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.12/dist-packages (4.9.9)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (0.8.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.13.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (4.2.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (1.17.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets) (4.67.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.23.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree->tensorflow-datasets) (25.4.0)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.12/dist-packages (from simple_parsing->tensorflow-datasets) (0.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.12/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.72.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow tensorflow-datasets pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us9mkPdMiHpd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "7d19b1d7f8064efca84ae8ba2361d7b9",
            "2ee5ca0269c74731944fbfc4d25e28ed",
            "5f038d313bb241a89f1e5ca6783a8e83",
            "f177be40d66a4493ac64e2eeea87b2e3",
            "a86684c1ad3947b08948e5bb10d746f3",
            "d116e34c0372440eb6c1911ad0cb5bb0",
            "c78f7093e87b4ff0831dcd34d5b60070",
            "6d85710d20a74c66a23e85915d449a7c",
            "b833fa1593ef483b92926341fccc3b10",
            "4c63151da3dd437496c0ae1538939910",
            "a4b039374c9641a6a5e6f6eaf7c0f705",
            "cd996794e90c41d3a1a53cb9e6a3586f",
            "cb92e434880e47d3b486d01e627b531c",
            "426ae309b0cf4513951f4662433f8f0e",
            "a93106a6c429464b9d18cf5a024df011",
            "af22542e64e841b9b8741d3533bd8b0f",
            "3fb25266a19b42d693cdf8ec20e5be2a",
            "fe4c5f212f52446a96e9013f1d505822",
            "a2c08593279e4f87b509cea2be08eab0",
            "878f3b29cd674eb49d5785432f208355",
            "c99032b49cf945e7b21e81de69e6ac1e",
            "787a985146bd44a0bb517cf572c32dd5",
            "c150f396d9c042a189d5cd70b51dfb06",
            "2be26422f93c4d1a8a4a587aedc41d90",
            "5357f340d8d449e8a211b371a3341b7e",
            "7cd9b1ce9f7c4b4abd6574c6a043c982",
            "6b6de440b9c24b17b3f13bdb98b21c04",
            "570bbdcc679d470aaa50b4b7ac36a2b4",
            "221a0d1229dd4e268df09194744f86a4",
            "083e38f4721d4643aab11e09a1a90971",
            "da1b95552bcf4456b441fcecb3b37334",
            "757d73897b874116ab4248c83011bb36",
            "c9556d9fbde34ccc8ce1153675b3bde6"
          ]
        },
        "outputId": "0d10af0a-2849-487c-a471-a5a8aa1f0e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Food-101 (this may take a while)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Variant folder /root/tensorflow_datasets/food101/2.0.0 has no dataset_info.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/food101/2.0.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d19b1d7f8064efca84ae8ba2361d7b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd996794e90c41d3a1a53cb9e6a3586f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c150f396d9c042a189d5cd70b51dfb06"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([\"pip\", \"install\", \"tensorflow\", \"tensorflow-datasets\"])\n",
        "    import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 224\n",
        "EPOCHS = 6   # increase later for better accuracy\n",
        "\n",
        "def preprocess(example):\n",
        "    image = tf.image.resize(example['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    label = example['label']\n",
        "    return image, label\n",
        "\n",
        "def prepare_datasets():\n",
        "    print(\"Downloading Food-101 (this may take a while)...\")\n",
        "    ds_train, ds_info = tfds.load(\n",
        "        'food101',\n",
        "        split='train',\n",
        "        with_info=True,\n",
        "        shuffle_files=True,\n",
        "        as_supervised=False\n",
        "    )\n",
        "    ds_test = tfds.load(\n",
        "        'food101',\n",
        "        split='validation',\n",
        "        as_supervised=False\n",
        "    )  # validation set is used as test in Food-101\n",
        "\n",
        "    num_classes = ds_info.features['label'].num_classes\n",
        "    print(f\"Found {num_classes} classes.\")\n",
        "\n",
        "    train = ds_train.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    train = train.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    val = ds_test.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    val = val.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return train, val, num_classes, ds_info\n",
        "\n",
        "def build_model(num_classes):\n",
        "    base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base.trainable = False  # freeze base for quick MVP\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = base(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    train_ds, val_ds, n_classes, ds_info = prepare_datasets()\n",
        "    model = build_model(n_classes)\n",
        "    print(model.summary())\n",
        "\n",
        "    # quick training\n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n",
        "\n",
        "    model_path = \"models/food101_mobilenetv2.h5\"\n",
        "    print(f\"Saving model to {model_path}\")\n",
        "    model.save(model_path)\n",
        "\n",
        "    # Save label names\n",
        "    label_names = ds_info.features['label'].names\n",
        "    import json\n",
        "    with open(\"models/label_names.json\", \"w\") as f:\n",
        "        json.dump(label_names, f)\n",
        "    print(\"Saved label names to models/label_names.json\")\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76e52af3"
      },
      "outputs": [],
      "source": [
        "%pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3P9TUJ-iZJs"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import io\n",
        "\n",
        "MODEL_PATH = \"models/food101_mobilenetv2.h5\"\n",
        "LABELS_PATH = \"models/label_names.json\"\n",
        "IMG_SIZE = 224\n",
        "\n",
        "st.set_page_config(page_title=\"FoodSave MVP\", layout=\"centered\")\n",
        "\n",
        "st.title(\"FoodSave — MVP\")\n",
        "st.write(\"Upload a food photo. The app will try to identify the food and suggest actions to reduce waste.\")\n",
        "\n",
        "# Load model\n",
        "model = None\n",
        "labels = None\n",
        "if os.path.exists(MODEL_PATH) and os.path.exists(LABELS_PATH):\n",
        "    import tensorflow as tf\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    with open(LABELS_PATH, \"r\") as f:\n",
        "        labels = json.load(f)\n",
        "else:\n",
        "    st.warning(\"Model not found. Run `python train_model.py` first to create the model.\")\n",
        "    st.info(\"You can still upload images to see local preview and suggestions.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption=\"Uploaded image\", use_column_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    if model is not None and labels is not None:\n",
        "        # preprocess\n",
        "        img = image.resize((IMG_SIZE, IMG_SIZE))\n",
        "        x = np.array(img) / 255.0\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "\n",
        "        preds = model.predict(x)[0]\n",
        "        top_idx = np.argsort(preds)[::-1][:3]\n",
        "        st.markdown(\"### Predictions (top 3):\")\n",
        "        for i in top_idx:\n",
        "            st.write(f\"- **{labels[i]}** — confidence: {preds[i]:.3f}\")\n",
        "\n",
        "        predicted = labels[top_idx[0]]\n",
        "\n",
        "        st.markdown(\"### Open Food Facts lookup (by predicted label)\")\n",
        "        try:\n",
        "            # simple search by predicted label\n",
        "            query = predicted.replace(\" \", \"+\")\n",
        "            url = f\"https://world.openfoodfacts.org/cgi/search.pl?search_terms={query}&search_simple=1&action=process&json=1&page_size=5\"\n",
        "            r = requests.get(url, timeout=10)\n",
        "            data = r.json()\n",
        "            if data.get(\"products\"):\n",
        "                st.write(f\"Found {len(data['products'])} product(s) related to *{predicted}* (sample):\")\n",
        "                for p in data[\"products\"][:3]:\n",
        "                    name = p.get(\"product_name\") or p.get(\"generic_name\") or \"Unnamed product\"\n",
        "                    brands = p.get(\"brands\", \"\")\n",
        "                    nutri = p.get(\"nutriments\", {})\n",
        "                    st.write(f\"- **{name}** — {brands}\")\n",
        "                    if 'expiration_date' in p:\n",
        "                        st.write(f\"  - expiry: {p['expiration_date']}\")\n",
        "                    # show minimal nutrition if exists\n",
        "                    if nutri:\n",
        "                        energy = nutri.get(\"energy-kcal_100g\") or nutri.get(\"energy_100g\")\n",
        "                        if energy:\n",
        "                            st.write(f\"  - energy (per 100g): {energy}\")\n",
        "            else:\n",
        "                st.write(\"No matching product found on Open Food Facts for this predicted label.\")\n",
        "        except Exception as e:\n",
        "            st.write(\"Open Food Facts lookup failed:\", e)\n",
        "\n",
        "        st.markdown(\"### Suggestions to reduce waste\")\n",
        "        st.write(\"- If expiry is near: cook soon or freeze.\")\n",
        "        st.write(\"- Convert to recipes that use leftover ingredients (soups, stir-fry).\")\n",
        "        st.write(\"- Share via community apps or donor platforms.\")\n",
        "    else:\n",
        "        st.info(\"Model not available. While the model is missing you can still use the app UI.\")\n",
        "        st.markdown(\"### Suggestions (based on generic rules)\")\n",
        "        st.write(\"- Smell & visual check for spoilage.\")\n",
        "        st.write(\"- If fruit/veg: use within 2–3 days or pickle/preserve.\")\n",
        "        st.write(\"- If packaged: check packaging & expiry date.\")\n",
        "\n",
        "st.sidebar.header(\"MVP Tips\")\n",
        "st.sidebar.write(\"1. Run `python train_model.py` to create the model (uses Food-101).\")\n",
        "st.sidebar.write(\"2. For better accuracy: increase epochs and unfreeze the base model.\")\n",
        "st.sidebar.write(\"3. Collect local photos using the app (consent) to fine-tune model for your region.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save model as pickle\n",
        "model_path_pkl = \"models/food101_mobilenetv2.pkl\"\n",
        "with open(model_path_pkl, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "print(f\"Saving model to {model_path_pkl}\")\n",
        "\n",
        "# Save label names as pickle\n",
        "label_names_path_pkl = \"models/label_names.pkl\"\n",
        "with open(label_names_path_pkl, \"wb\") as f:\n",
        "    pickle.dump(labels, f)\n",
        "print(f\"Saved label names to {label_names_path_pkl}\")"
      ],
      "metadata": {
        "id": "22rcspyYFFeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate_and_generate_figures_with_shap.py\n",
        "\"\"\"\n",
        "Validation + explainability script for the programmer retention study.\n",
        "Outputs in ./validation_results/\n",
        "- cv_summary.csv\n",
        "- confusion_matrices.json\n",
        "- policy_simulation.json\n",
        "- perm_<model>.csv and perm_<model>.png\n",
        "- shap_<model>_summary.png and shap_<model>_mean_abs.csv (if shap available)\n",
        "\"\"\"\n",
        "\n",
        "import os, json, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "# optional libraries\n",
        "try:\n",
        "    import xgboost as xgb; HAS_XGB=True\n",
        "except: HAS_XGB=False\n",
        "try:\n",
        "    import lightgbm as lgb; HAS_LGB=True\n",
        "except: HAS_LGB=False\n",
        "try:\n",
        "    import catboost as cb; HAS_CAT=True\n",
        "except: HAS_CAT=False\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    HAS_IMB=True\n",
        "except: HAS_IMB=False\n",
        "try:\n",
        "    import shap; HAS_SHAP=True\n",
        "except: HAS_SHAP=False\n",
        "\n",
        "# -------- CONFIG --------\n",
        "INPUT_CSV = \"/content/dataf n.csv\"       # path to your uploaded CSV\n",
        "OUT_DIR = \"validation_results\"\n",
        "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
        "FOLDS = 5                       # CV folds (set to 5 or 10)\n",
        "BOOT_ITERS = 300                # bootstrap iters for CI (reduce to speed up)\n",
        "RANDOM_STATE = 0\n",
        "# ------------------------\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# load CSV\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "# autodetect target (adjust heuristics if needed)\n",
        "target_col = None\n",
        "for c in df.columns:\n",
        "    low = c.lower()\n",
        "    if \"intend\" in low and \"technology\" in low:\n",
        "        target_col = c; break\n",
        "if target_col is None:\n",
        "    # fallback: any column containing 'intend' or 'seek'\n",
        "    for c in df.columns:\n",
        "        if \"intend\" in c.lower() or \"seek employment\" in c.lower():\n",
        "            target_col = c; break\n",
        "if target_col is None:\n",
        "    raise ValueError(\"Target column not found. Columns: \" + \", \".join(df.columns[:30]))\n",
        "\n",
        "# drop obvious PII columns\n",
        "drop_cols = [c for c in df.columns if any(k in c.lower() for k in [\"timestamp\", \"email\", \"name\", \"enter your\"])]\n",
        "df_clean = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
        "\n",
        "# target mapping: yes-like -> 1\n",
        "y = df_clean[target_col].astype(str).str.lower().str.contains(\"yes|intend|would\").astype(int)\n",
        "\n",
        "# feature selection heuristic: pick common survey columns\n",
        "candidates = []\n",
        "for col in df_clean.columns:\n",
        "    low = col.lower()\n",
        "    if col == target_col:\n",
        "        continue\n",
        "    if any(k in low for k in [\"age\",\"gender\",\"living\",\"residence\",\"income\",\"cgpa\",\"prior\",\"program\",\"family encourage\",\"parent\",\"hours\",\"proficiency\",\"interest in technology\"]):\n",
        "        candidates.append(col)\n",
        "if len(candidates) < 6:\n",
        "    # fallback: first 12 non-target columns\n",
        "    candidates = [c for c in df_clean.columns if c != target_col][:12]\n",
        "\n",
        "X = df_clean[candidates].copy()\n",
        "# normalize text-like categories\n",
        "for c in X.select_dtypes(include='object').columns:\n",
        "    X[c] = X[c].fillna(\"missing\").astype(str).str.strip().str.replace(r\"\\s+\", \"_\", regex=True).str.lower()\n",
        "\n",
        "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "num_cols = X.select_dtypes(exclude='object').columns.tolist()\n",
        "\n",
        "# preprocessor\n",
        "cat_tf = Pipeline([('imp', SimpleImputer(strategy='constant', fill_value='missing')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "num_tf = Pipeline([('imp', SimpleImputer(strategy='median')), ('sc', StandardScaler())])\n",
        "preprocessor = ColumnTransformer([('num', num_tf, num_cols), ('cat', cat_tf, cat_cols)], remainder='drop')\n",
        "\n",
        "# models list\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear', random_state=RANDOM_STATE),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, class_weight='balanced'),\n",
        "    'SVM': SVC(probability=True, random_state=RANDOM_STATE),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'NaiveBayes': GaussianNB(),\n",
        "    'MLP': MLPClassifier(max_iter=500, random_state=RANDOM_STATE)\n",
        "}\n",
        "if HAS_XGB: models['XGBoost'] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
        "if HAS_LGB: models['LightGBM'] = lgb.LGBMClassifier(random_state=RANDOM_STATE)\n",
        "if HAS_CAT: models['CatBoost'] = cb.CatBoostClassifier(verbose=0, random_state=RANDOM_STATE)\n",
        "\n",
        "def stratified_cv(pipe, Xdf, yser, folds=5):\n",
        "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    accs, f1s, aucs = [], [], []\n",
        "    for train_idx, test_idx in skf.split(Xdf, yser):\n",
        "        Xtr, Xte = Xdf.iloc[train_idx], Xdf.iloc[test_idx]\n",
        "        ytr, yte = yser.iloc[train_idx], yser.iloc[test_idx]\n",
        "        # Check if the classifier requires dense input\n",
        "        if isinstance(pipe.named_steps['clf'], (GaussianNB, SVC, MLPClassifier)): # Add other classifiers that need dense if necessary\n",
        "             Xtr_processed = pipe.named_steps['pre'].fit_transform(Xtr).toarray()\n",
        "             Xte_processed = pipe.named_steps['pre'].transform(Xte).toarray()\n",
        "             pipe.named_steps['clf'].fit(Xtr_processed, ytr)\n",
        "             yp = pipe.named_steps['clf'].predict(Xte_processed)\n",
        "             try:\n",
        "                 probs = pipe.named_steps['clf'].predict_proba(Xte_processed)[:,1]\n",
        "             except:\n",
        "                 probs = np.full(len(yte), np.nan)\n",
        "        else:\n",
        "            pipe.fit(Xtr, ytr)\n",
        "            yp = pipe.predict(Xte)\n",
        "            try:\n",
        "                probs = pipe.predict_proba(Xte)[:,1]\n",
        "            except:\n",
        "                probs = np.full(len(yte), np.nan)\n",
        "\n",
        "        accs.append(accuracy_score(yte, yp))\n",
        "        f1s.append(f1_score(yte, yp, zero_division=0))\n",
        "        aucs.append(roc_auc_score(yte, probs) if not np.all(np.isnan(probs)) else np.nan)\n",
        "\n",
        "    return np.array(accs), np.array(f1s), np.array(aucs)\n",
        "\n",
        "def bootstrap_ci(arr, iters=300):\n",
        "    # Ensure arr is a numpy array\n",
        "    arr = np.asarray(arr)\n",
        "    arr = arr[~np.isnan(arr)]\n",
        "    if len(arr) == 0:\n",
        "        return (float('nan'), float('nan'))\n",
        "    bs = [np.mean(np.random.choice(arr, size=len(arr), replace=True)) for _ in range(iters)]\n",
        "    return (float(np.percentile(bs, 2.5)), float(np.percentile(bs, 97.5)))\n",
        "\n",
        "summary_rows = []\n",
        "# MAIN: evaluate no-resample and resample\n",
        "for scenario in ['no_resample', 'resample']:\n",
        "    for mname, clf in models.items():\n",
        "        pipe = Pipeline([('pre', preprocessor), ('clf', clf)])\n",
        "        if scenario == 'no_resample':\n",
        "            accs, f1s, aucs = stratified_cv(pipe, X, y, folds=FOLDS)\n",
        "        else:\n",
        "            # manual resampling inside CV folds\n",
        "            accs, f1s, aucs = [], [], []\n",
        "            skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "            for train_idx, test_idx in skf.split(X, y):\n",
        "                Xtr, Xte = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
        "                ytr, yte = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
        "                train = pd.concat([Xtr, ytr.rename('target')], axis=1)\n",
        "                maj = train[train['target'] == train['target'].mode()[0]]\n",
        "                minr = train[train['target'] != train['target'].mode()[0]]\n",
        "                if len(minr) == 0:\n",
        "                    # Check if the classifier requires dense input\n",
        "                    if isinstance(pipe.named_steps['clf'], (GaussianNB, SVC, MLPClassifier)):\n",
        "                         Xtr_processed = pipe.named_steps['pre'].fit_transform(Xtr).toarray()\n",
        "                         Xte_processed = pipe.named_steps['pre'].transform(Xte).toarray()\n",
        "                         pipe.named_steps['clf'].fit(Xtr_processed, ytr)\n",
        "                         yp = pipe.named_steps['clf'].predict(Xte_processed)\n",
        "                         try:\n",
        "                            probs = pipe.named_steps['clf'].predict_proba(Xte_processed)[:,1]\n",
        "                         except:\n",
        "                            probs = np.full(len(yte), np.nan)\n",
        "                    else:\n",
        "                        pipe.fit(Xtr, ytr)\n",
        "                        yp = pipe.predict(Xte)\n",
        "                        try:\n",
        "                           probs = pipe.predict_proba(Xte)[:,1]\n",
        "                        except:\n",
        "                           probs = np.full(len(yte), np.nan)\n",
        "\n",
        "                    accs.append(accuracy_score(yte, yp)); f1s.append(f1_score(yte, yp, zero_division=0))\n",
        "                    aucs.append(roc_auc_score(yte, probs) if not np.all(np.isnan(probs)) else np.nan)\n",
        "                    continue\n",
        "                # try SMOTE on transformed features if available\n",
        "                if HAS_IMB:\n",
        "                    # fit preprocessor, transform training, apply SMOTE, fit clf on transformed features\n",
        "                    pre = preprocessor.fit(Xtr, ytr)\n",
        "                    Xtr_t = pre.transform(Xtr)\n",
        "                    try:\n",
        "                        sm = SMOTE(random_state=RANDOM_STATE)\n",
        "                        X_res_t, y_res = sm.fit_resample(Xtr_t, ytr)\n",
        "                        # fit classifier on transformed features directly\n",
        "                        clf_t = clf\n",
        "                        # Check if the classifier requires dense input\n",
        "                        if isinstance(clf_t, (GaussianNB, SVC, MLPClassifier)):\n",
        "                            clf_t.fit(X_res_t.toarray(), y_res)\n",
        "                        else:\n",
        "                            clf_t.fit(X_res_t, y_res)\n",
        "\n",
        "                        # evaluate by transforming Xte\n",
        "                        Xte_t = pre.transform(Xte)\n",
        "                        # Check if the classifier requires dense input\n",
        "                        if isinstance(clf_t, (GaussianNB, SVC, MLPClassifier)):\n",
        "                             yp = clf_t.predict(Xte_t.toarray())\n",
        "                        else:\n",
        "                             yp = clf_t.predict(Xte_t)\n",
        "\n",
        "                        accs.append(accuracy_score(yte, yp)); f1s.append(f1_score(yte, yp, zero_division=0))\n",
        "                        try:\n",
        "                            # Check if the classifier requires dense input for predict_proba\n",
        "                            if isinstance(clf_t, (GaussianNB, SVC, MLPClassifier)):\n",
        "                                aucs.append(roc_auc_score(yte, clf_t.predict_proba(Xte_t.toarray())[:,1]))\n",
        "                            else:\n",
        "                                aucs.append(roc_auc_score(yte, clf_t.predict_proba(Xte_t)[:,1]))\n",
        "                        except:\n",
        "                            aucs.append(np.nan)\n",
        "                        continue\n",
        "                    except Exception:\n",
        "                        # fallback to simple upsampling below\n",
        "                        pass\n",
        "                # simple upsampling fallback\n",
        "                from sklearn.utils import resample\n",
        "                minr_up = resample(minr, replace=True, n_samples=len(maj), random_state=RANDOM_STATE)\n",
        "                train_res = pd.concat([maj, minr_up])\n",
        "                y_res = train_res['target']; X_res = train_res.drop(columns=['target'])\n",
        "                # Check if the classifier requires dense input\n",
        "                if isinstance(pipe.named_steps['clf'], (GaussianNB, SVC, MLPClassifier)):\n",
        "                     X_res_processed = pipe.named_steps['pre'].fit_transform(X_res).toarray()\n",
        "                     Xte_processed = pipe.named_steps['pre'].transform(Xte).toarray()\n",
        "                     pipe.named_steps['clf'].fit(X_res_processed, y_res)\n",
        "                     yp = pipe.named_steps['clf'].predict(Xte_processed)\n",
        "                     try:\n",
        "                        probs = pipe.named_steps['clf'].predict_proba(Xte_processed)[:,1]\n",
        "                     except:\n",
        "                        probs = np.full(len(yte), np.nan)\n",
        "                else:\n",
        "                    pipe.fit(X_res, y_res)\n",
        "                    yp = pipe.predict(Xte)\n",
        "                    try:\n",
        "                        probs = pipe.predict_proba(Xte)[:,1]\n",
        "                    except:\n",
        "                        probs = np.full(len(yte), np.nan)\n",
        "\n",
        "                accs.append(accuracy_score(yte, yp)); f1s.append(f1_score(yte, yp, zero_division=0))\n",
        "                aucs.append(roc_auc_score(yte, probs) if not np.all(np.isnan(probs)) else np.nan)\n",
        "\n",
        "        # summarize\n",
        "        acc_mean, acc_std = float(np.nanmean(accs)), float(np.nanstd(accs))\n",
        "        f1_mean, f1_std = float(np.nanmean(f1s)), float(np.nanstd(f1s))\n",
        "        auc_mean, auc_std = float(np.nanmean(aucs)), float(np.nanstd(aucs))\n",
        "        acc_ci = bootstrap_ci(accs, iters=BOOT_ITERS)\n",
        "        f1_ci = bootstrap_ci(f1s, iters=BOOT_ITTERS)\n",
        "        auc_ci = bootstrap_ci(np.array(aucs)[~np.isnan(aucs)], iters=BOOT_ITTERS) if not np.all(np.isnan(aucs)) else (float('nan'), float('nan'))\n",
        "        summary_rows.append({\n",
        "            'scenario': scenario, 'model': mname,\n",
        "            'accuracy_mean': acc_mean, 'accuracy_std': acc_std, 'accuracy_ci95': acc_ci,\n",
        "            'f1_mean': f1_mean, 'f1_std': f1_std, 'f1_ci95': f1_ci,\n",
        "            'auc_mean': auc_mean, 'auc_std': auc_std, 'auc_ci95': auc_ci\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(os.path.join(OUT_DIR, \"cv_summary.csv\"), index=False)\n",
        "\n",
        "# Train-test holdout for confusion matrices + importances (use upsampled train to help minority)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "confusion_dict = {}\n",
        "perm_files = []\n",
        "shap_files = []\n",
        "for mname, clf in models.items():\n",
        "    pipe = Pipeline([('pre', preprocessor), ('clf', clf)])\n",
        "    # simple upsample training\n",
        "    train_df = pd.concat([X_train, y_train.rename('target')], axis=1)\n",
        "    maj = train_df[train_df['target'] == train_df['target'].mode()[0]]\n",
        "    minr = train_df[train_df['target'] != train_df['target'].mode()[0]]\n",
        "    if len(minr) > 0:\n",
        "        from sklearn.utils import resample\n",
        "        minr_up = resample(minr, replace=True, n_samples=len(maj), random_state=RANDOM_STATE)\n",
        "        train_res_df = pd.concat([maj, minr_up]); y_res = train_res_df['target']; X_res = train_res_df.drop(columns=['target'])\n",
        "        # Check if the classifier requires dense input\n",
        "        if isinstance(pipe.named_steps['clf'], (GaussianNB, SVC, MLPClassifier)):\n",
        "            X_res_processed = pipe.named_steps['pre'].fit_transform(X_res).toarray()\n",
        "            pipe.named_steps['clf'].fit(X_res_processed, y_res)\n",
        "        else:\n",
        "            pipe.fit(X_res, y_res)\n",
        "    else:\n",
        "         # Check if the classifier requires dense input\n",
        "        if isinstance(pipe.named_steps['clf'], (GaussianNB, SVC, MLPClassifier)):\n",
        "            X_train_processed = pipe.named_steps['pre'].fit_transform(X_train).toarray()\n",
        "            pipe.named_steps['clf'].fit(X_train_processed, y_train)\n",
        "        else:\n",
        "            pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    # Check if the classifier requires dense input\n",
        "    if isinstance(pipe.named_steps['clf'], (GaussianNB, SVC, MLPClassifier)):\n",
        "        X_test_processed = pipe.named_steps['pre'].transform(X_test).toarray()\n",
        "        yp = pipe.named_steps['clf'].predict(X_test_processed)\n",
        "    else:\n",
        "        yp = pipe.predict(X_test)\n",
        "\n",
        "    confusion_dict[mname] = confusion_matrix(y_test, yp).tolist()\n",
        "\n",
        "    # permutation importance (on transformed features)\n",
        "    try:\n",
        "        Xt = pipe.named_steps['pre'].transform(X_test)\n",
        "        clf_fitted = pipe.named_steps['clf']\n",
        "        # Check if the classifier or permutation_importance requires dense input\n",
        "        if isinstance(clf_fitted, (GaussianNB, SVC, MLPClassifier)):\n",
        "             Xt_dense = Xt.toarray()\n",
        "             imp = permutation_importance(clf_fitted, Xt_dense, y_test, n_repeats=10, random_state=RANDOM_STATE)\n",
        "        else:\n",
        "             imp = permutation_importance(clf_fitted, Xt, y_test, n_repeats=10, random_state=RANDOM_STATE)\n",
        "\n",
        "        try:\n",
        "            feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
        "        except:\n",
        "            feat_names = [f\"f{i}\" for i in range(len(imp.importances_mean))]\n",
        "        imp_df = pd.DataFrame({'feature': feat_names, 'importance_mean': imp.importances_mean, 'importance_std': imp.importances_std})\n",
        "        imp_df = imp_df.sort_values('importance_mean', ascending=False).head(40)\n",
        "        fname = os.path.join(OUT_DIR, f\"perm_{mname}.csv\")\n",
        "        imp_df.to_csv(fname, index=False); perm_files.append(fname)\n",
        "        # plot top 10\n",
        "        top = imp_df.head(10).iloc[::-1]\n",
        "        plt.figure(figsize=(6,4)); plt.barh(top['feature'], top['importance_mean']); plt.title(f\"Permutation importance - {mname}\")\n",
        "        plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, f\"perm_{mname}.png\"), dpi=300); plt.close()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # SHAP (if available): use model-specific explainer where appropriate. Save mean absolute SHAP per original feature.\n",
        "    if HAS_SHAP:\n",
        "        try:\n",
        "            # transform train and test using preprocessor\n",
        "            pre_fit = pipe.named_steps['pre'].fit(X_train, y_train)\n",
        "            Xtr_t = pre_fit.transform(X_train)\n",
        "            Xte_t = pre_fit.transform(X_test)\n",
        "            clf_fitted = pipe.named_steps['clf']\n",
        "            # choose explainer\n",
        "            if mname in ['XGBoost'] and HAS_XGB:\n",
        "                expl = shap.TreeExplainer(clf_fitted)\n",
        "            elif mname in ['RandomForest','DecisionTree'] and hasattr(clf_fitted, 'estimators_'):\n",
        "                expl = shap.TreeExplainer(clf_fitted)\n",
        "            else:\n",
        "                # Check if the classifier requires dense input for the explainer\n",
        "                if isinstance(clf_fitted, (GaussianNB, SVC, MLPClassifier)):\n",
        "                     expl = shap.Explainer(clf_fitted.predict_proba if hasattr(clf_fitted, \"predict_proba\") else clf_fitted.predict, Xtr_t.toarray())\n",
        "                else:\n",
        "                     expl = shap.Explainer(clf_fitted.predict_proba if hasattr(clf_fitted, \"predict_proba\") else clf_fitted.predict, Xtr_t)\n",
        "            # Check if the classifier requires dense input for SHAP values calculation\n",
        "            if isinstance(clf_fitted, (GaussianNB, SVC, MLPClassifier)):\n",
        "                 shap_vals = expl(Xte_t.toarray())\n",
        "            else:\n",
        "                 shap_vals = expl(Xte_t)\n",
        "\n",
        "            # summarize mean(|SHAP|)\n",
        "            # shap_vals may be array-like; convert to 2D numeric for mean abs\n",
        "            try:\n",
        "                arr = np.abs(shap_vals.values if hasattr(shap_vals, \"values\") else np.array(shap_vals))\n",
        "            except:\n",
        "                arr = np.abs(np.array(shap_vals))\n",
        "            mean_abs = np.mean(arr, axis=0)\n",
        "            try:\n",
        "                feat_names = pre_fit.get_feature_names_out()\n",
        "            except:\n",
        "                feat_names = [f\"f{i}\" for i in range(len(mean_abs))]\n",
        "            shap_df = pd.DataFrame({'feature': feat_names, 'mean_abs_shap': mean_abs}).sort_values('mean_abs_shap', ascending=False).head(50)\n",
        "            sfile = os.path.join(OUT_DIR, f\"shap_{mname}_mean_abs.csv\"); shap_files.append(sfile)\n",
        "            # plot SHAP summary (requires shap plotting)\n",
        "            try:\n",
        "                import matplotlib\n",
        "                plt.figure(figsize=(6,4))\n",
        "                # Check if the classifier requires dense input for shap.summary_plot\n",
        "                if isinstance(clf_fitted, (GaussianNB, SVC, MLPClassifier)):\n",
        "                     shap.summary_plot(shap_vals, features=X_test.to_numpy(), feature_names=feat_names, show=False, max_display=15)\n",
        "                else:\n",
        "                     shap.summary_plot(shap_vals, features=X_test, feature_names=feat_names, show=False, max_display=15)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(FIG_DIR, f\"shap_summary_{mname}.png\"), dpi=300)\n",
        "                plt.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "        except Exception:\n",
        "            # fail gracefully and continue\n",
        "            pass\n",
        "\n",
        "# save confusion matrices\n",
        "with open(os.path.join(OUT_DIR, \"confusion_matrices.json\"), \"w\") as f:\n",
        "    json.dump(confusion_dict, f, indent=2)\n",
        "\n",
        "# POLICY SIMULATION (safe)\n",
        "living_col = None\n",
        "for c in X.columns:\n",
        "    if \"living\" in c.lower() or \"residence\" in c.lower():\n",
        "        living_col = c; break\n",
        "\n",
        "policy = None\n",
        "if living_col and 'LogisticRegression' in models:\n",
        "    pipe_lr = Pipeline([('pre', preprocessor), ('clf', models['LogisticRegression'])])\n",
        "    # fit on upsampled train to be consistent\n",
        "    train_df = pd.concat([X_train, y_train.rename('target')], axis=1)\n",
        "    maj = train_df[train_df['target'] == train_df['target'].mode()[0]]\n",
        "    minr = train_df[train_df['target'] != train_df['target'].mode()[0]]\n",
        "    if len(minr) > 0:\n",
        "        from sklearn.utils import resample\n",
        "        minr_up = resample(minr, replace=True, n_samples=len(maj), random_state=RANDOM_STATE)\n",
        "        train_res_df = pd.concat([maj, minr_up]); y_res = train_res_df['target']; X_res = train_res_df.drop(columns=['target'])\n",
        "        pipe_lr.fit(X_res, y_res)\n",
        "    else:\n",
        "        pipe_lr.fit(X_train, y_train)\n",
        "    Xc = X_test.copy(); Xc[living_col] = Xc[living_col].astype(str)\n",
        "    rural_mask = Xc[living_col].str.contains(\"rural\", na=False)\n",
        "    if rural_mask.sum() > 0:\n",
        "        sample_size = max(1, int(np.ceil(0.1 * rural_mask.sum())))\n",
        "        rural_idx = Xc[rural_mask].sample(n=sample_size, random_state=RANDOM_STATE).index\n",
        "        before = float(pipe_lr.predict_proba(Xc)[:,1].mean())\n",
        "        X_alt = Xc.copy(); X_alt.loc[rural_idx, living_col] = \"urban\"\n",
        "        after = float(pipe_lr.predict_proba(X_alt)[:,1].mean())\n",
        "        policy = {'living_col': living_col, 'n_rural': int(rural_mask.sum()), 'changed': int(len(rural_idx)),\n",
        "                  'mean_prob_before': before, 'mean_prob_after': after, 'delta': after - before}\n",
        "        with open(os.path.join(OUT_DIR, \"policy_simulation.json\"), \"w\") as f:\n",
        "            json.dump(policy, f, indent=2)\n",
        "\n",
        "# final report\n",
        "report = {\n",
        "    'n_rows': int(df.shape[0]), 'n_features_used': int(X.shape[1]),\n",
        "    'models_evaluated': list(models.keys()),\n",
        "    'has_imblearn': bool(HAS_IMB), 'has_shap': bool(HAS_SHAP),\n",
        "    'cv_summary_csv': os.path.join(OUT_DIR, \"cv_summary.csv\"),\n",
        "    'confusion_matrices': os.path.join(OUT_DIR, \"confusion_matrices.json\"),\n",
        "    'perm_files_count': len([f for f in os.listdir(OUT_DIR) if f.startswith(\"perm_\")]),\n",
        "    'shap_files_count': len(shap_files),\n",
        "    'policy_simulation': policy\n",
        "}\n",
        "with open(os.path.join(OUT_DIR, \"run_report.json\"), \"w\") as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print(\"Validation completed. Outputs in:\", OUT_DIR)\n",
        "print(\"Run report:\", json.dumps(report, indent=2))"
      ],
      "metadata": {
        "id": "duNhM7UKwfPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate_and_generate_figures_with_shap.py\n",
        "\"\"\"\n",
        "Validation + explainability script for programmer retention study.\n",
        "Outputs to ./validation_results/\n",
        "\n",
        "- cv_summary.csv (cross-validation results with mean, std, CI)\n",
        "- confusion_matrices.json\n",
        "- policy_simulation.json\n",
        "- perm_<model>.csv and perm_<model>.png\n",
        "- shap_<model>_summary.png and shap_<model>_mean_abs.csv (if shap available)\n",
        "\"\"\"\n",
        "\n",
        "import os, json, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "# optional libraries\n",
        "try: import xgboost as xgb; HAS_XGB=True\n",
        "except: HAS_XGB=False\n",
        "try: import lightgbm as lgb; HAS_LGB=True\n",
        "except: HAS_LGB=False\n",
        "try: import catboost as cb; HAS_CAT=True\n",
        "except: HAS_CAT=False\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    HAS_IMB=True\n",
        "except: HAS_IMB=False\n",
        "try:\n",
        "    import shap; HAS_SHAP=True\n",
        "except: HAS_SHAP=False\n",
        "\n",
        "# -------- CONFIG --------\n",
        "INPUT_CSV = \"/content/dataf n.csv\"  # path to your dataset\n",
        "OUT_DIR = \"validation_results\"\n",
        "FIG_DIR = os.path.join(OUT_DIR, \"figures\")\n",
        "FOLDS = 5\n",
        "BOOT_ITERS = 300\n",
        "RANDOM_STATE = 0\n",
        "# ------------------------\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# load\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "target_col = None\n",
        "for c in df.columns:\n",
        "    low = c.lower()\n",
        "    if \"intend\" in low and \"technology\" in low:\n",
        "        target_col = c; break\n",
        "if target_col is None:\n",
        "    for c in df.columns:\n",
        "        if \"intend\" in c.lower() or \"seek employment\" in c.lower():\n",
        "            target_col = c; break\n",
        "if target_col is None:\n",
        "    raise ValueError(\"Target column not found.\")\n",
        "\n",
        "drop_cols = [c for c in df.columns if any(k in c.lower() for k in [\"timestamp\", \"email\", \"name\", \"enter your\"])]\n",
        "df_clean = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
        "\n",
        "y = df_clean[target_col].astype(str).str.lower().str.contains(\"yes|intend|would\").astype(int)\n",
        "\n",
        "candidates = []\n",
        "for col in df_clean.columns:\n",
        "    if col == target_col: continue\n",
        "    low = col.lower()\n",
        "    if any(k in low for k in [\"age\",\"gender\",\"living\",\"residence\",\"income\",\"cgpa\",\"prior\",\"program\",\"family\",\"parent\",\"hours\",\"proficiency\",\"interest\"]):\n",
        "        candidates.append(col)\n",
        "if len(candidates) < 6:\n",
        "    candidates = [c for c in df_clean.columns if c != target_col][:12]\n",
        "\n",
        "X = df_clean[candidates].copy()\n",
        "for c in X.select_dtypes(include='object').columns:\n",
        "    X[c] = X[c].fillna(\"missing\").astype(str).str.strip().str.replace(r\"\\s+\",\"_\",regex=True).str.lower()\n",
        "\n",
        "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "num_cols = X.select_dtypes(exclude='object').columns.tolist()\n",
        "\n",
        "# --- FIX: force dense output ---\n",
        "cat_tf = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "])\n",
        "num_tf = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='median')),\n",
        "    ('sc', StandardScaler())\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_tf, num_cols),\n",
        "    ('cat', cat_tf, cat_cols)\n",
        "], remainder='drop')\n",
        "\n",
        "# models\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear', random_state=RANDOM_STATE),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, class_weight='balanced'),\n",
        "    'SVM': SVC(probability=True, random_state=RANDOM_STATE),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'NaiveBayes': GaussianNB(),\n",
        "    'MLP': MLPClassifier(max_iter=500, random_state=RANDOM_STATE)\n",
        "}\n",
        "if HAS_XGB: models['XGBoost'] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
        "if HAS_LGB: models['LightGBM'] = lgb.LGBMClassifier(random_state=RANDOM_STATE)\n",
        "if HAS_CAT: models['CatBoost'] = cb.CatBoostClassifier(verbose=0, random_state=RANDOM_STATE)\n",
        "\n",
        "def stratified_cv(pipe, Xdf, yser, folds=5):\n",
        "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    accs, f1s, aucs = [], [], []\n",
        "    for tr, te in skf.split(Xdf, yser):\n",
        "        Xtr, Xte = Xdf.iloc[tr], Xdf.iloc[te]\n",
        "        ytr, yte = yser.iloc[tr], yser.iloc[te]\n",
        "        pipe.fit(Xtr, ytr)\n",
        "        yp = pipe.predict(Xte)\n",
        "        accs.append(accuracy_score(yte, yp))\n",
        "        f1s.append(f1_score(yte, yp, zero_division=0))\n",
        "        try:\n",
        "            probs = pipe.predict_proba(Xte)[:,1]\n",
        "            aucs.append(roc_auc_score(yte, probs))\n",
        "        except:\n",
        "            aucs.append(np.nan)\n",
        "    return np.array(accs), np.array(f1s), np.array(aucs)\n",
        "\n",
        "def bootstrap_ci(arr, iters=300):\n",
        "    arr = np.array(arr[~np.isnan(arr)])\n",
        "    if len(arr) == 0: return (float('nan'), float('nan'))\n",
        "    bs = [np.mean(np.random.choice(arr, size=len(arr), replace=True)) for _ in range(iters)]\n",
        "    return (float(np.percentile(bs, 2.5)), float(np.percentile(bs, 97.5)))\n",
        "\n",
        "# --- CV evaluation ---\n",
        "summary_rows = []\n",
        "for scenario in ['no_resample','resample']:\n",
        "    for mname, clf in models.items():\n",
        "        pipe = Pipeline([('pre', preprocessor), ('clf', clf)])\n",
        "        if scenario == 'no_resample':\n",
        "            accs, f1s, aucs = stratified_cv(pipe, X, y, folds=FOLDS)\n",
        "        else:\n",
        "            # fallback simple upsampling\n",
        "            accs,f1s,aucs=[],[],[]\n",
        "            skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "            for tr,te in skf.split(X,y):\n",
        "                Xtr,Xte = X.iloc[tr].copy(), X.iloc[te].copy()\n",
        "                ytr,yte = y.iloc[tr].copy(), y.iloc[te].copy()\n",
        "                train = pd.concat([Xtr,ytr.rename('target')],axis=1)\n",
        "                maj = train[train['target']==train['target'].mode()[0]]\n",
        "                minr = train[train['target']!=train['target'].mode()[0]]\n",
        "                if len(minr)==0: continue\n",
        "                from sklearn.utils import resample\n",
        "                minr_up=resample(minr,replace=True,n_samples=len(maj),random_state=RANDOM_STATE)\n",
        "                train_res=pd.concat([maj,minr_up])\n",
        "                y_res=train_res['target']; X_res=train_res.drop(columns=['target'])\n",
        "                pipe.fit(X_res,y_res)\n",
        "                yp=pipe.predict(Xte)\n",
        "                accs.append(accuracy_score(yte,yp)); f1s.append(f1_score(yte,yp,zero_division=0))\n",
        "                try: aucs.append(roc_auc_score(yte,pipe.predict_proba(Xte)[:,1]))\n",
        "                except: aucs.append(np.nan)\n",
        "        summary_rows.append({\n",
        "            'scenario':scenario,'model':mname,\n",
        "            'acc_mean':float(np.nanmean(accs)),'f1_mean':float(np.nanmean(f1s)),'auc_mean':float(np.nanmean(aucs)),\n",
        "            'acc_ci95':bootstrap_ci(accs,BOOT_ITERS),'f1_ci95':bootstrap_ci(f1s,BOOT_ITERS),\n",
        "            'auc_ci95':bootstrap_ci(aucs,BOOT_ITERS) if not np.all(np.isnan(aucs)) else (np.nan,np.nan)\n",
        "        })\n",
        "\n",
        "pd.DataFrame(summary_rows).to_csv(os.path.join(OUT_DIR,\"cv_summary.csv\"),index=False)\n",
        "\n",
        "# --- Confusion matrices ---\n",
        "Xtr,Xte,ytr,yte=train_test_split(X,y,stratify=y,test_size=0.2,random_state=RANDOM_STATE)\n",
        "cms={}\n",
        "for mname,clf in models.items():\n",
        "    pipe=Pipeline([('pre',preprocessor),('clf',clf)]); pipe.fit(Xtr,ytr)\n",
        "    yp=pipe.predict(Xte); cms[mname]=confusion_matrix(yte,yp).tolist()\n",
        "with open(os.path.join(OUT_DIR,\"confusion_matrices.json\"),\"w\") as f: json.dump(cms,f,indent=2)\n",
        "\n",
        "# --- Policy simulation ---\n",
        "living_col=None\n",
        "for c in X.columns:\n",
        "    if \"living\" in c.lower() or \"residence\" in c.lower(): living_col=c; break\n",
        "policy=None\n",
        "if living_col and 'LogisticRegression' in models:\n",
        "    pipe_lr=Pipeline([('pre',preprocessor),('clf',models['LogisticRegression'])]); pipe_lr.fit(Xtr,ytr)\n",
        "    Xc=Xte.copy(); Xc[living_col]=Xc[living_col].astype(str)\n",
        "    rural_mask=Xc[living_col].str.contains(\"rural\",na=False)\n",
        "    if rural_mask.sum()>0:\n",
        "        idx=Xc[rural_mask].sample(frac=0.1,random_state=RANDOM_STATE).index\n",
        "        before=float(pipe_lr.predict_proba(Xc)[:,1].mean())\n",
        "        Xalt=Xc.copy(); Xalt.loc[idx,living_col]=\"urban\"\n",
        "        after=float(pipe_lr.predict_proba(Xalt)[:,1].mean())\n",
        "        policy={'living_col':living_col,'n_rural':int(rural_mask.sum()),'changed':len(idx),'before':before,'after':after,'delta':after-before}\n",
        "        with open(os.path.join(OUT_DIR,\"policy_simulation.json\"),\"w\") as f: json.dump(policy,f,indent=2)\n",
        "\n",
        "print(\"Done. Results in:\",OUT_DIR)"
      ],
      "metadata": {
        "id": "fXgmleusxONk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "# Load your confusion matrices\n",
        "with open(\"validation_results/confusion_matrices.json\", \"r\") as f:\n",
        "    cms = json.load(f)\n",
        "\n",
        "# Class labels\n",
        "labels = [\"Not Retained\", \"Retained\"]\n",
        "\n",
        "# Export each confusion matrix\n",
        "for model, cm in cms.items():\n",
        "    cm = np.array(cm)\n",
        "    fig, ax = plt.subplots(figsize=(3, 3))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=labels, yticklabels=labels, cbar=False, ax=ax)\n",
        "\n",
        "    ax.set_xlabel(\"Predicted Label\")\n",
        "    ax.set_ylabel(\"True Label\")\n",
        "    ax.set_title(model)\n",
        "\n",
        "    # Clean file name (lowercase, no spaces)\n",
        "    fname = \"confusion_\" + model.lower().replace(\" \", \"\") + \".png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"validation_results/figures/{fname}\", dpi=300)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "CsjyfjXx7K4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ix2l3R8VYrXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d19b1d7f8064efca84ae8ba2361d7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ee5ca0269c74731944fbfc4d25e28ed",
              "IPY_MODEL_5f038d313bb241a89f1e5ca6783a8e83",
              "IPY_MODEL_f177be40d66a4493ac64e2eeea87b2e3"
            ],
            "layout": "IPY_MODEL_a86684c1ad3947b08948e5bb10d746f3"
          }
        },
        "2ee5ca0269c74731944fbfc4d25e28ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d116e34c0372440eb6c1911ad0cb5bb0",
            "placeholder": "​",
            "style": "IPY_MODEL_c78f7093e87b4ff0831dcd34d5b60070",
            "value": "Dl Completed...:   0%"
          }
        },
        "5f038d313bb241a89f1e5ca6783a8e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d85710d20a74c66a23e85915d449a7c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b833fa1593ef483b92926341fccc3b10",
            "value": 0
          }
        },
        "f177be40d66a4493ac64e2eeea87b2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c63151da3dd437496c0ae1538939910",
            "placeholder": "​",
            "style": "IPY_MODEL_a4b039374c9641a6a5e6f6eaf7c0f705",
            "value": " 0/1 [02:51&lt;?, ? url/s]"
          }
        },
        "a86684c1ad3947b08948e5bb10d746f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d116e34c0372440eb6c1911ad0cb5bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78f7093e87b4ff0831dcd34d5b60070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d85710d20a74c66a23e85915d449a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b833fa1593ef483b92926341fccc3b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c63151da3dd437496c0ae1538939910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b039374c9641a6a5e6f6eaf7c0f705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd996794e90c41d3a1a53cb9e6a3586f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb92e434880e47d3b486d01e627b531c",
              "IPY_MODEL_426ae309b0cf4513951f4662433f8f0e",
              "IPY_MODEL_a93106a6c429464b9d18cf5a024df011"
            ],
            "layout": "IPY_MODEL_af22542e64e841b9b8741d3533bd8b0f"
          }
        },
        "cb92e434880e47d3b486d01e627b531c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb25266a19b42d693cdf8ec20e5be2a",
            "placeholder": "​",
            "style": "IPY_MODEL_fe4c5f212f52446a96e9013f1d505822",
            "value": "Dl Size...:  64%"
          }
        },
        "426ae309b0cf4513951f4662433f8f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c08593279e4f87b509cea2be08eab0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_878f3b29cd674eb49d5785432f208355",
            "value": 1
          }
        },
        "a93106a6c429464b9d18cf5a024df011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c99032b49cf945e7b21e81de69e6ac1e",
            "placeholder": "​",
            "style": "IPY_MODEL_787a985146bd44a0bb517cf572c32dd5",
            "value": " 3067/4764 [02:51&lt;01:46, 15.98 MiB/s]"
          }
        },
        "af22542e64e841b9b8741d3533bd8b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb25266a19b42d693cdf8ec20e5be2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4c5f212f52446a96e9013f1d505822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2c08593279e4f87b509cea2be08eab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "878f3b29cd674eb49d5785432f208355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c99032b49cf945e7b21e81de69e6ac1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "787a985146bd44a0bb517cf572c32dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c150f396d9c042a189d5cd70b51dfb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2be26422f93c4d1a8a4a587aedc41d90",
              "IPY_MODEL_5357f340d8d449e8a211b371a3341b7e",
              "IPY_MODEL_7cd9b1ce9f7c4b4abd6574c6a043c982"
            ],
            "layout": "IPY_MODEL_6b6de440b9c24b17b3f13bdb98b21c04"
          }
        },
        "2be26422f93c4d1a8a4a587aedc41d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_570bbdcc679d470aaa50b4b7ac36a2b4",
            "placeholder": "​",
            "style": "IPY_MODEL_221a0d1229dd4e268df09194744f86a4",
            "value": "Extraction completed...: "
          }
        },
        "5357f340d8d449e8a211b371a3341b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_083e38f4721d4643aab11e09a1a90971",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da1b95552bcf4456b441fcecb3b37334",
            "value": 0
          }
        },
        "7cd9b1ce9f7c4b4abd6574c6a043c982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757d73897b874116ab4248c83011bb36",
            "placeholder": "​",
            "style": "IPY_MODEL_c9556d9fbde34ccc8ce1153675b3bde6",
            "value": " 0/0 [02:51&lt;?, ? file/s]"
          }
        },
        "6b6de440b9c24b17b3f13bdb98b21c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570bbdcc679d470aaa50b4b7ac36a2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "221a0d1229dd4e268df09194744f86a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "083e38f4721d4643aab11e09a1a90971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "da1b95552bcf4456b441fcecb3b37334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "757d73897b874116ab4248c83011bb36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9556d9fbde34ccc8ce1153675b3bde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}